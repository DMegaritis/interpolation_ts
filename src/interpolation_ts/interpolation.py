import pandas as pd
import numpy as np
import warnings
from scipy.interpolate import PchipInterpolator
from typing import Iterable


class Interpolation:
    """
    Align any number of time-series datasets to a uniform time grid using PCHIP interpolation.

    Args:
        None (instance has no state)

    Usage:
        interp = Interpolation()
        aligned_dfs = interp.interpolate([df1, df2, df3], sampling_rate_hz=100, overlap_windows=True)
        # aligned_dfs is a tuple (df1_aligned, df2_aligned, df3_aligned)
    """

    def __init__(self):
        pass

    def interpolate(
        self,
        dfs: Iterable[pd.DataFrame] | tuple[pd.DataFrame, pd.DataFrame],
        *,
        sampling_rate_hz: float = 100,
        overlap_windows: bool = False
    ) -> tuple[pd.DataFrame, ...]:
        # Backwards-compatible: accept (df1, df2) as two positional args too
        if not isinstance(dfs, (list, tuple)):
            raise TypeError("dfs must be a list or tuple of pandas.DataFrame")
        if len(dfs) < 1:
            raise ValueError("Provide at least one DataFrame")

        # ** Clean input dataframes individually
        clean_dfs = []
        starts = []
        ends = []
        for df in dfs:
            df = df.copy()
            if 'time' not in df.columns:
                raise ValueError("Each DataFrame must have a 'time' column")
            if not np.issubdtype(df['time'].dtype, np.datetime64):
                df['time'] = pd.to_datetime(df['time'])
            # remove non-increasing timestamps (keep strictly increasing)
            df = df[df['time'].diff().fillna(pd.Timedelta(seconds=1)) > pd.Timedelta(0)]
            df = df.reset_index(drop=True)
            if df.shape[0] == 0:
                warnings.warn("One of the input DataFrames became empty after removing non-increasing timestamps.", UserWarning)
            clean_dfs.append(df)
            if df.shape[0] > 0:
                starts.append(df['time'].iloc[0])
                ends.append(df['time'].iloc[-1])
            else:
                # placeholder times so global bounds ignore empty dfs
                starts.append(pd.Timestamp.max)
                ends.append(pd.Timestamp.min)

        # Use cleaned dfs from now on
        dfs = clean_dfs

        # ** Check overlap across all non-empty dfs
        non_empty_indices = [i for i, df in enumerate(dfs) if df.shape[0] > 0]
        overlap = True
        if len(non_empty_indices) == 0:
            # nothing to interpolate: return empty frames
            return tuple(pd.DataFrame(columns=[]) for _ in dfs)

        latest_start = max(starts[i] for i in non_empty_indices)
        earliest_end = min(ends[i] for i in non_empty_indices)
        print(latest_start, earliest_end)
        if latest_start > earliest_end:
            overlap = False
            warnings.warn(
                f"No temporal overlap between datasets:\n"
                + "\n".join(
                    f"  df{i} range = [{(dfs[i]['time'].iloc[0] if dfs[i].shape[0]>0 else 'empty')}, "
                    f"{(dfs[i]['time'].iloc[-1] if dfs[i].shape[0]>0 else 'empty')}]"
                    for i in range(len(dfs))
                ),
                UserWarning
            )

        # ** Build union of columns (excluding 'time') so outputs share same columns
        all_cols = []
        for df in dfs:
            cols = [c for c in df.columns if c != 'time']
            for c in cols:
                if c not in all_cols:
                    all_cols.append(c)
        cols = all_cols  # final ordered list of columns
        n_cols = len(cols)

        # ** Build target time grid across min start and max end (ignoring empty dfs)
        t_start = min(starts[i] for i in non_empty_indices)
        t_end = max(ends[i] for i in non_empty_indices)
        duration_s = (t_end - t_start).total_seconds()
        n_samples = max(1, int(duration_s * sampling_rate_hz))

        if n_samples == 1:
            t_target_ns = np.array([t_start.value], dtype=np.int64)
        else:
            t_target_float = np.linspace(float(t_start.value), float(t_end.value), n_samples)
            t_target_ns = np.rint(t_target_float).astype(np.int64)
        t_target = pd.to_datetime(t_target_ns)

        # ** Preallocate arrays for interpolated values and masks (one per input df)
        arrays_interp = [np.zeros((n_samples, n_cols), dtype=float) for _ in range(len(dfs))]
        masks = [np.zeros(n_samples, dtype=bool) for _ in range(len(dfs))]

        # ** For each df, do PCHIP interpolation for the columns that exist in that df.
        for i, df in enumerate(dfs):
            if df.shape[0] == 0:
                # leave as zeros and mask stays False
                continue

            x_ns = df['time'].values.astype('int64')

            # mask True for points inside original data range
            masks[i] = (t_target_ns >= x_ns.min()) & (t_target_ns <= x_ns.max())

            # For columns not present in df, we keep zeros (consistent with outside-range fill)
            for j, col in enumerate(cols):
                if col not in df.columns:
                    # column absent in this df: leave zeros
                    continue
                y = df[col].values.astype(float)
                # only interpolate if we have >=2 points; else rely on injection of originals
                if df.shape[0] >= 2:
                    try:
                        interp_fn = PchipInterpolator(x_ns.astype(float), y, extrapolate=False)
                        y_interp = interp_fn(t_target_ns.astype(float))
                    except Exception as e:
                        # fallback: set zeros and rely on injection
                        y_interp = np.zeros(n_samples, dtype=float)
                    # fill outside original data range with 0 (explicit)
                    y_interp[t_target_ns < x_ns.min()] = 0.0
                    y_interp[t_target_ns > x_ns.max()] = 0.0
                    arrays_interp[i][:, j] = y_interp
                else:
                    # single-sample df: leave zeros for now; injection below will add the original value
                    arrays_interp[i][:, j] = 0.0

        # ** Inject original sample values at nearest grid index (average if multiple map to same index)
        def inject_originals(arr_interp, df):
            if df.shape[0] == 0:
                return arr_interp
            x_ns = df['time'].values.astype('int64')
            if n_samples == 1:
                idx = np.zeros_like(x_ns, dtype=np.int64)
            else:
                step = float(t_target_ns[1] - t_target_ns[0])
                rel = (x_ns - t_target_ns[0]).astype(np.float64) / step
                idx = np.rint(rel).astype(np.int64)
                idx = np.clip(idx, 0, n_samples - 1)

            # For each column present in df, average values per index and place them in arr_interp
            for j, col in enumerate(cols):
                if col not in df.columns:
                    continue
                sums = np.zeros(n_samples, dtype=float)
                counts = np.zeros(n_samples, dtype=int)
                vals = df[col].values.astype(float)
                for k, idk in enumerate(idx):
                    sums[idk] += vals[k]
                    counts[idk] += 1
                mask_idx = counts > 0
                if np.any(mask_idx):
                    avg = np.zeros_like(sums)
                    avg[mask_idx] = sums[mask_idx] / counts[mask_idx]
                    arr_interp[mask_idx, j] = avg[mask_idx]
            return arr_interp

        for i, df in enumerate(dfs):
            arrays_interp[i] = inject_originals(arrays_interp[i], df)

        # ** Build DataFrames with mask column for cropping logic
        dfs_interp = []
        for i in range(len(dfs)):
            df_interp = pd.DataFrame(arrays_interp[i], columns=cols, index=t_target)
            df_interp['valid'] = masks[i]
            dfs_interp.append(df_interp)

        # ** Crop to overlapping window across all dfs' valid masks if requested
        if overlap_windows:
            if overlap:
                mask_overlap = np.ones(n_samples, dtype=bool)
                for m in masks:
                    mask_overlap &= m
                # if mask_overlap all False -> result will be empty
                dfs_interp = [df.iloc[mask_overlap] for df in dfs_interp]
            else:
                warnings.warn(
                    "Cannot crop to overlapping window because the datasets have no temporal overlap.",
                    UserWarning
                )

        # ** Drop the mask column before returning
        for i in range(len(dfs_interp)):
            if 'valid' in dfs_interp[i].columns:
                dfs_interp[i] = dfs_interp[i].drop(columns='valid')

        return tuple(dfs_interp)
